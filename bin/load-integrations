#!/usr/bin/env perl
use 5.010;
use strict;
use warnings;
use utf8;
use open qw< :std :encoding(UTF-8) >;
use FindBin qw< $Bin >;
use lib "$Bin/../lib";
use Getopt::Long::Descriptive;
use Hash::Fold 0.001002;
use ISDB::Schema;
use Text::CSV;
use Time::HiRes qw< time >;
use Try::Tiny;

my ($opt, $usage) = describe_options(
    '%c [--dry-run] [--validate] [integrations.csv]',
    [],
    [ "Loads integration site observations into the ISDB.  Input is CSV, either" ],
    [ "specified by files on the command line or from stdin." ],
    [],
    [ 'no-in-vitro', "don't insert integrations which happened in vitro" ],
    [],
    [ 'dry-run',  "insert data but rollback the transaction at the end" ],
    [ 'validate', "validate rows and gene info, but don't try to insert any data; implies --dry-run", { implies => 'dry_run' } ],
    [ 'help',     "print usage message and exit" ],
);

print($usage->text), exit(!$opt->help)
    if $opt->help or (not @ARGV and -t STDIN);

$SIG{__WARN__} = sub {
    warn "Warning: ", @_;
};

main();

sub main {
    my $db    = ISDB::Schema->connect_default;
    my $txn   = $db->txn_scope_guard;
    my $is    = $db->resultset("Integration");
    my $line  = 0;
    my $inserted = 0;

    say "Loading integration sites... ";
    while (my $row = read_input()) {
        $line++;
        $inserted += try {
            $row = normalize($db, $row);

            return 0 if $opt->no_in_vitro
                    and $row->{environment} eq "in vitro";

            $is->create($row)
                unless $opt->validate;
            return 1;
        } catch {
            s/ at \S+ line \d+//;
            if ($opt->validate) {
                warn "Error: $_, input line $line";
                return 0;
            } else {
                die "Error: $_, input line $line";
            }
        };
        report_status($line, every => 1000);
    }
    report_status($line, every => 1);
    say "$inserted observations inserted";

    die "This was a DRY RUN, aborting transaction.\n"
        if $opt->dry_run;
    $txn->commit;
    say "OK";
}

sub report_status {
    state $start = time;
    my $count    = shift;
    my $every    = { @_ }->{every} || 1000;
    my $elapsed  = time - $start;
    printf "$count lines processed in %0.3f seconds (%0.0f lines/s)\n",
        $elapsed, $count / $elapsed
            if $count % $every == 0;
}

sub normalize {
    my ($db, $row) = @_;

    state $hash = Hash::Fold->new(
        array_delimiter => '/#',
        hash_delimiter  => '/',
    );

    # Normalize empty strings into NULL
    $_ = undef for grep { not length } values %$row;

    # Reconstitute any flattened structures; encoding JSON fields back to JSON
    # is handled by our schema classes
    $row = $hash->unflatten($row);

    # We now look this up in the database by intersecting the IS location with
    # gene locations.
    delete $row->{ncbi_gene_id};
    delete $row->{gene};
    delete $row->{orientation_in_gene};

    $row->{landmark}                ||= delete $row->{chromosome};
    $row->{orientation_in_landmark} ||= delete $row->{orientation_in_reference};

    $row->{landmark} = "chr$row->{landmark}"
        if $row->{landmark}
       and $row->{landmark} =~ /^(\d+|[XY]|MT)$/;

    return $row;
}

sub read_input {
    state $file;
    state $csv  = Text::CSV->new({
        binary => 1,
    }) or die "Can't create new Text::CSV: " . Text::CSV->error_diag . "\n";

    my $row      = $csv->getline(*ARGV);
    my $new_file = (not $file or $file ne $ARGV);

    say "Finished file: $file"
        if ($new_file and $file) or not $row;

    return undef unless $row;

    if ($new_file) {
        # We got the header of a new file.
        $csv->column_names(@$row);
        $row = $csv->getline(*ARGV);

        say "Started file: ", $file = $ARGV;
    }
    my %row;
    @row{ $csv->column_names } = @$row;
    return \%row;
}
